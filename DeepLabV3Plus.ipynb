{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepLabV3Plus.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "ZQLIPzyTPKgN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import cv2\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from PIL import Image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rCzLD-hctcEY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "!wget https://www.dropbox.com/s/pxcz2wdz04zxocq/CamVid.zip?dl=1 -O CamVid.zip\n",
        "!unzip CamVid.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "81Ns-zNXPcuL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class SeparableConv2d(nn.Module):\n",
        "    def __init__(self,in_channels,out_channels,kernel_size=1,stride=1,padding=0,dilation=1,bias=False):\n",
        "        super(SeparableConv2d,self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels,in_channels,kernel_size,stride,padding,dilation,groups=in_channels,bias=bias)\n",
        "        self.pointwise = nn.Conv2d(in_channels,out_channels,1,1,0,1,1,bias=bias)\n",
        "    \n",
        "    def forward(self,x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.pointwise(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "  def __init__(self,in_channels,out_channels,side_branch = True):\n",
        "    super(ConvBlock,self).__init__()\n",
        "    \n",
        "    self.in_channels = in_channels\n",
        "    self.out_channels = out_channels\n",
        "    self.side_branch = side_branch\n",
        "    \n",
        "    self.relu = nn.ReLU()\n",
        "    \n",
        "    self.sep_conv1 = SeparableConv2d(in_channels = self.in_channels,\n",
        "                          out_channels = self.out_channels,\n",
        "                          kernel_size = 3,\n",
        "                          padding = 1)\n",
        "    self.sep_conv2 = SeparableConv2d(in_channels = self.out_channels,\n",
        "                          out_channels = self.out_channels,\n",
        "                          kernel_size = 3,\n",
        "                          padding = 1)\n",
        "    self.sep_conv3 = SeparableConv2d(in_channels = self.in_channels,\n",
        "                          out_channels = self.out_channels,\n",
        "                          kernel_size = 3,\n",
        "                          padding = 1,\n",
        "                          stride = 2)\n",
        "    self.conv4 = nn.Conv2d(in_channels = self.in_channels,\n",
        "                          out_channels = self.out_channels,\n",
        "                          kernel_size = 1,\n",
        "                          padding = 1,\n",
        "                          stride = 2)\n",
        "    self.batchnorm = nn.BatchNorm2d()\n",
        "      \n",
        "        \n",
        "  def forward(self,x):\n",
        "    main = self.sep_conv1(x)    \n",
        "    main = self.batchnorm(main)\n",
        "    main = self.relu(main)\n",
        "    main = self.sep_conv2(x)    \n",
        "    main = self.batchnorm(main)\n",
        "    main = self.relu(main)\n",
        "    main = self.sep_conv3(x)    \n",
        "    main = self.batchnorm(main)\n",
        "    main = self.relu(main)\n",
        "    \n",
        "    if side_branch:\n",
        "      side = F.relu(self.conv4(x))\n",
        "      \n",
        "    try:\n",
        "      return side + main\n",
        "    \n",
        "    except:\n",
        "      return x + main\n",
        "    \n",
        "\n",
        "    \n",
        "    \n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BZB5EdUfXW2A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class ASSP(nn.Module):\n",
        "  def __init__(self,in_channels,out_channels = 256):\n",
        "    super(ASSP,self).__init__()\n",
        "    \n",
        "    self.bn = nn.BatchNorm2d(out_channels)\n",
        "    self.relu = nn.ReLU()\n",
        "    \n",
        "    self.conv1 = nn.Conv2d(in_channels = in_channels, \n",
        "                          out_channels = out_channels,\n",
        "                          kernel_size = 1,\n",
        "                          padding = 1)\n",
        "    self.conv2 = nn.Conv2d(in_channels = in_channels, \n",
        "                          out_channels = out_channels,\n",
        "                          kernel_size = 3,\n",
        "                          padding = 6,\n",
        "                          dilation = 6)\n",
        "    self.conv3 = nn.Conv2d(in_channels = in_channels, \n",
        "                          out_channels = out_channels,\n",
        "                          kernel_size = 3,\n",
        "                          padding = 12,\n",
        "                          dilation = 12)\n",
        "    self.conv4 = nn.Conv2d(in_channels = in_channels, \n",
        "                          out_channels = out_channels,\n",
        "                          kernel_size = 3,\n",
        "                          padding = 18,\n",
        "                          dilation = 18)\n",
        "    self.adapool = nn.AdaptiveAvgPool2d((1,1))\n",
        "   \n",
        "  \n",
        "  def forward(self,x):\n",
        "    x1 = self.conv1(x)\n",
        "    x1 = self.bn(x1)\n",
        "    x1 = self.relu(x1)\n",
        "    x2 = self.conv2(x)\n",
        "    x2 = self.bn(x2)\n",
        "    x2 = self.relu(x2)\n",
        "    x3 = self.conv3(x)\n",
        "    x3 = self.bn(x3)\n",
        "    x3 = self.relu(x3)\n",
        "    x4 = self.conv4(x)\n",
        "    x4 = self.bn(x4)\n",
        "    x4 = self.relu(x4)\n",
        "    x5 = self.adapool(x)\n",
        "    x5 = self.conv1(x5)\n",
        "    x5 = self.nb(x5)\n",
        "    x5 = self.relu(x5)\n",
        "    \n",
        "    x6 = torch.cat((x1,x2,x3,x4,x5), dim = 1) #channels first\n",
        "    x6 = self.conv1(x6)\n",
        "    x6 = self.bn(x6)\n",
        "    \n",
        "    return self.relu(x6)\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "79q09zhHtj7O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Checking if there is any gpu available and pass the model to gpu or cpu\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "enet = enet.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eAaPS_hFtt7O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def loader(training_path, segmented_path, batch_size, h=320, w=1000):\n",
        "    filenames_t = os.listdir(training_path)\n",
        "    total_files_t = len(filenames_t)\n",
        "    \n",
        "    filenames_s = os.listdir(segmented_path)\n",
        "    total_files_s = len(filenames_s)\n",
        "    \n",
        "    assert(total_files_t == total_files_s)\n",
        "    \n",
        "    if str(batch_size).lower() == 'all':\n",
        "        batch_size = total_files_s\n",
        "    \n",
        "    idx = 0\n",
        "    while(1):\n",
        "      # Choosing random indexes of images and labels\n",
        "        batch_idxs = np.random.randint(0, total_files_s, batch_size)\n",
        "            \n",
        "        \n",
        "        inputs = []\n",
        "        labels = []\n",
        "        \n",
        "        for jj in batch_idxs:\n",
        "          # Reading normalized photo\n",
        "            img = plt.imread(training_path + filenames_t[jj])\n",
        "          # Resizing using nearest neighbor method\n",
        "            img = cv2.resize(img, (h, w), cv2.INTER_NEAREST)\n",
        "            inputs.append(img)\n",
        "          \n",
        "          # Reading semantic image\n",
        "            img = Image.open(segmented_path + filenames_s[jj])\n",
        "            img = np.array(img)\n",
        "          # Resizing using nearest neighbor method\n",
        "            img = cv2.resize(img, (h, w), cv2.INTER_NEAREST)\n",
        "            labels.append(img)\n",
        "         \n",
        "        inputs = np.stack(inputs, axis=2)\n",
        "      # Changing image format to C x H x W\n",
        "        inputs = torch.tensor(inputs).transpose(0, 2).transpose(1, 3)\n",
        "        \n",
        "        labels = torch.tensor(labels)\n",
        "        \n",
        "        yield inputs, labels"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}